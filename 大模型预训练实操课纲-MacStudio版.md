# 🤖 大模型预训练实操课纲（Mac Studio 本地版）

> 基于 Metal/MLX 生态，专注原理理解与工程实践
> 硬件：Mac Studio (M2 Ultra, 128GB 统一内存)

---

## 📖 课程理念

### 视频核心观点回顾

> "看过数十篇论文不如自己训过一次模型"
> "预训练的大部分坑，1B的模型会遇到，100B的模型也会遇到"
> "核心的工程方法论是相通的"
> "你要向面试官证明的不是'我烧过多少钱'，而是'我知道怎么做'"

### 本课程的特殊定位

| 维度 | 视频原版 | 本课程（Mac Studio） |
|------|---------|---------------------|
| 硬件 | A100 云端算力 | M2 Ultra 本地 Metal |
| 规模 | 1B-7B 模型 | 100M-500M 模型 |
| 重点 | 训练大模型 | 理解核心原理 + 小模型验证 |
| 时长 | 一个月密集训练 | 两个月深度学习 |
| 产出 | 一个训练好的模型 | 完整知识体系 + 可讲的经验 |

**核心论点不变**：
- ✅ 坑是相通的（小模型坑 ≈ 大模型坑）
- ✅ 真正的经验来自"制造事故"和"解决问题"
- ✅ 面试要证明"我知道怎么做"

---

## 🎯 整体架构

### 课程三阶段

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   阶段一：原理理解（理解"为什么"）                           │
│   ├── 第一章：神经网络基础回顾                              │
│   ├── 第二章：从头理解语言模型                              │
│   ├── 第三章：优化器与学习率的本质                          │
│   └── 第四章：数据工程的深层逻辑                           │
│                                                             │
│   阶段二：代码实现（亲手"做"）                              │
│   ├── 第五章：手写训练框架                                  │
│   ├── 第六章：数据管道实现                                  │
│   ├── 第七章：Metal 加速实践                                │
│   └── 第八章：训练监控与调试                                │
│                                                             │
│   阶段三：实验验证（踩坑 + 总结）                           │
│   ├── 第九章：故意制造事故                                  │
│   ├── 第十章：系统性对比实验                                │
│   └── 第十一章：复盘与面试素材                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 时间规划

| 阶段 | 周次 | 主题 | 每日投入 |
|------|------|------|---------|
| **一** | 第1-2周 | 原理理解 | 1-2小时/天 |
| **二** | 第3-4周 | 代码实现 | 2-3小时/天 |
| **三** | 第5-6周 | 实验验证 | 1-2小时/天 |

---

# 📚 阶段一：原理理解

> **核心目标**：在写任何代码之前，先建立完整的概念框架
> **学习方法**：阅读 + 思考问题 + 写笔记

---

## 第一章：神经网络基础回顾

### 学习目标

| 目标 | 描述 | 判断标准 |
|------|------|---------|
| 理解前向传播 | 知道数据如何变成预测 | 能手算简单网络的输出 |
| 理解反向传播 | 知道梯度如何计算和传播 | 能解释链式法则 |
| 理解参数更新 | 知道优化器如何改变参数 | 能手写简单的 SGD |

### 阅读材料

| 材料 | 章节 | 预计时间 |
|------|------|---------|
| 《动手学深度学习》或 fast.ai 课程 | 第2-4章 | 3-4小时 |
| 3Blue1Brown 神经网络系列视频 | 全部 | 2小时 |
| CS231n 笔记（可选） | 反向传播部分 | 2小时 |

### 💭 引导思考问题

在阅读过程中，思考以下问题（不要急着找答案，写下你的初步想法）：

#### Q1：前向传播的本质

```
问题：神经网络本质上在做什么？

提示：
- 输入 x 经过层层变换得到输出 y
- 每一层做了什么变换？
- 这些变换的参数是从哪来的？
- 如果没有参数会怎样？

你的初步想法：
_______________________________________________
_______________________________________________
_______________________________________________
```

```
追问1：为什么需要"多层"网络？

- 单层线性变换：y = Wx + b
- 多层非线性变换：y = W₂(W₁x + b₁) + b₂

如果只用单层，我们能表达什么？
如果加了激活函数，我们能表达什么？
单层 + 激活 vs 多层，区别在哪？

你的初步想法：
_______________________________________________
_______________________________________________
```

```
追问2：激活函数为什么必须是非线性的？

- 如果所有层都是线性的：W₂(W₁x) = (W₂W₁)x = W'x
- 这等价于单层变换

这意味着什么？
如果没有非线性激活，堆叠100层和堆叠1层有什么区别？
"非线性"在这里具体指的是什么数学性质？

你的初步想法：
_______________________________________________
_______________________________________________
```

#### Q2：反向传播的本质

```
问题：反向传播在传播什么？

提示：
- 前向：从输入到输出
- 反向：从输出到输入

梯度是从哪来的？
它要告诉每一层的参数什么信息？
如果梯度是零，意味着什么？

你的初步想法：
_______________________________________________
_______________________________________________
```

```
追问：链式法则在这里起什么作用？

- ∂L/∂W₁ = ∂L/∂y × ∂y/∂h × ∂h/∂W₁

每一项代表什么？
为什么是"相乘"而不是"相加"？
相乘意味着什么风险（梯度消失/爆炸）？

你的初步想法：
_______________________________________________
_______________________________________________
```

#### Q3：参数更新的本质

```
问题：W ← W - lr × ∂L/∂W，这个公式在做什么？

- lr（学习率）的作用是什么？
- 为什么要"减去"梯度？
- 如果 lr 太大会发生什么？
- 如果 lr 太小会发生什么？

你的初步想法：
_______________________________________________
_______________________________________________
```

### 实践练习

在理解了上述概念后，完成以下练习（用纸笔或代码）：

| 练习 | 描述 | 验收标准 |
|------|------|---------|
| 练习 1.1 | 手算一个 2×2×1 的网络前向传播 | 能解释每一步 |
| 练习 1.2 | 手算同一个网络的反向传播 | 能解释链式法则 |
| 练习 1.3 | 用 NumPy 实现上述网络 | 代码能运行，Loss 下降 |

---

## 第二章：从头理解语言模型

### 学习目标

| 目标 | 描述 | 判断标准 |
|------|------|---------|
| 理解 Token | 知道什么是 token，为什么需要分词 | 能解释"词"和"token"的区别 |
| 理解 Embedding | 知道词如何变成向量 | 能手算简单词的 embedding |
| 理解 Attention | 知道 Transformer 的核心机制 | 能画图解释 Q、K、V |
| 理解 Next Token Prediction | 知道语言模型如何训练 | 能解释训练目标 |

### 阅读材料

| 材料 | 章节 | 预计时间 |
|------|------|---------|
| The Illustrated Transformer | 全部 | 1.5小时 |
| GPT-3 论文（可选） | Introduction + Method | 2小时 |
| 分词入门 | BPE/WordPiece/SentencePiece | 1小时 |

### 💭 引导思考问题

#### Q1：Token 的本质

```
问题：为什么不能直接用"词"？

- 英文词汇量：10万-100万+
- 中文词汇量：几乎无限（组合无穷）
- 常用汉字：3500个

如果用"词"作为单位，问题是什么？
如果用"字"作为单位，问题是什么？
BPE 的核心思想是什么？

你的初步想法：
_______________________________________________
_______________________________________________
```

```
追问：分词质量如何影响模型？

案例：
- "中华人民共和国" 可以分词为：
  方案A：["中华人民共和国"]
  方案B：["中华", "人民", "共和国"]
  方案C：["中", "华", "人", "民", "共", "和", "国"]

对模型来说，这三种方案有什么区别？
哪种方案 token 数最多？最少？
对训练速度和模型能力有什么影响？

你的初步想法：
_______________________________________________
_______________________________________________
```

```
压缩率练习：计算不同分词方案的压缩率

文本："中华人民共和国"

| 方案 | Token数 | 字符数 | 压缩率 |
|------|---------|-------|--------|
| 字 | 7 | 7 | 1.0 |
| 词A | 1 | 7 | 7.0 |
| 词B | 3 | 7 | 2.33 |

压缩率 = 字符数 / Token数，越高越好

思考：
- 为什么词A的压缩率最高？
- 压缩率越高越好吗？有什么代价？
- 实际中如何在压缩率和泛化性之间平衡？

你的初步想法：
_______________________________________________
_______________________________________________
```

#### Q2：Embedding 的本质

```
问题：Embedding 向量到底是什么？

- 一个词 → 一个 768 维向量
- 这个向量是怎么来的？
- 相似的词，向量应该有什么特点？
- "狗"和"猫"的向量距离 vs "狗"和"汽车"的向量距离

你的初步想法：
_______________________________________________
_______________________________________________
```

```
追问：为什么需要高维向量？

- 2维向量能区分多少语义关系？
- 768维向量能区分多少？
- 如果维度太低，会发生什么"维度灾难"？
- 维度越高越好吗？有什么代价？

你的初步想法：
_______________________________________________
_______________________________________________
```

#### Q3：Attention 的本质

```
问题：Attention 机制在解决什么问题？

没有 Attention 的序列模型（RNN/LSTM）：
- 信息需要"走"过整个序列才能被利用
- 距离越长，信息衰减越严重

有 Attention 的 Transformer：
- 任意两个位置可以直接"对话"
- 通过 Q、K、V 计算相关性

尝试用一句话解释 Attention：
"Attention 就是___________________________________________"

你的答案：
_______________________________________________
```

```
追问：Q、K、V 分别代表什么？

- Query（查询）："我在找什么信息"
- Key（键）："我这里有什么信息"
- Value（值）："如果匹配上，我给你什么"

生活类比：
- 在图书馆找书：
  - Query：我想找"关于深度学习的书"
  - Key：每本书的标签/摘要
  - Value：书的具体内容

Query 和 Key 匹配后，为什么需要 Value？
如果直接返回 Key 会怎样？

你的初步想法：
_______________________________________________
```

```
计算练习：简化版 Attention

假设只有 2 个词：
- "我" 的 embedding: [1, 0]
- "爱" 的 embedding: [0, 1]

简化计算（不做 softmax，直接用点积）：
- "我" 对 "我" 的 attention：1×1 + 0×0 = 1
- "我" 对 "爱" 的 attention：1×0 + 0×1 = 0
- "爱" 对 "我" 的 attention：0×1 + 1×0 = 0
- "爱" 对 "爱" 的 attention：0×0 + 1×1 = 1

这意味着：
- "我" 会"关注"自己 100%
- "爱" 会"关注"自己 100%
- 两个词之间没有交流

这合理吗？
如果加上可学习的 W_Q、W_K，会发生什么变化？

你的想法：
_______________________________________________
```

#### Q4：Next Token Prediction 的本质

```
问题：语言模型的训练目标是什么？

给定上文的 token，预测下一个 token

例子：
- 文本："今天天气很好"
- 输入："今天天气" → 输出："好"

训练时，模型对每个位置都做预测：
- 位置1：根据"今"预测"天"
- 位置2：根据"今天"预测"天"
- 位置3：根据"今天天"预测"气"
- ...

为什么这样设计？
这种目标和"理解"有什么关系？
和 BERT 的 [MASK] 预测有什么区别？

你的初步想法：
_______________________________________________
```

```
追问：训练数据中的 "正确答案" 从哪来？

- 训练目标：P("下一个 token" | "前文")
- 真实分布：语料库中的实际文本
- 损失函数：Cross Entropy

如果文本是："今天天气很好"
模型预测 "晴"，但真实是 "好"
这算是模型"错"了吗？

你的想法：
_______________________________________________
```

### 实践练习

| 练习 | 描述 | 验收标准 |
|------|------|---------|
| 练习 2.1 | 用 Python 实现 BPE 分词器 | 能解释每一步逻辑 |
| 练习 2.2 | 手算 3×3 self-attention | 能解释计算过程 |
| 练习 2.3 | 写一段话解释 Attention | 8岁小孩能听懂 |

---

## 第三章：优化器与学习率的核心逻辑

### 学习目标

| 目标 | 描述 | 判断标准 |
|------|------|---------|
| 理解 SGD | 知道基本参数更新规则 | 能手写 SGD 更新 |
| 理解 Momentum | 知道动量如何加速收敛 | 能解释物理类比 |
| 理解 Adam | 知道自适应学习率的原理 | 能解释一阶/二阶矩估计 |
| 理解 Warmup | 知道预热阶段的作用 | 能解释为什么需要 |

### 💭 引导思考问题

#### Q1：为什么需要优化器？

```
问题：直接沿着梯度方向走不就行了吗？为什么要有各种优化器？

SGD: W = W - lr × grad

这已经很直观了：
- 梯度指向 loss 下降最快的方向
- 沿着这个方向走就行

那为什么会有 Adam、RMSProp、Momentum...？
它们在解决 SGD 的什么问题？

你的初步想法：
_______________________________________________
```

```
SGD 的问题 1：振荡

        \
         \    (正确的下降方向)
          \________
         /      /
        /      /
       /      /

如果梯度在某些方向大、某些方向小，
SGD 会怎么走？
这会导致什么问题？

你的想法：
_______________________________________________
```

```
SGD 的问题 2：陷入局部最优

    /----(局部最优)
   /    
--/     
   \    
    \-----(全局最优)

梯度为零的地方，就是最优解吗？
局部最优和全局最优有什么区别？
SGD 能跳出局部最优吗？

你的想法：
_______________________________________________
```

#### Q2：Momentum 的物理直觉

```
问题：Momentum 为什么叫"动量"？

想象一个球从山上滚下来：
- 速度慢的地方：慢慢滚
- 速度快的地方：冲过小山

在优化中：
- 没有 momentum：每一步都重新判断方向
- 有 momentum：记住之前的方向，惯性前进

Momentum 系数（比如 0.9）是什么意思？
如果设为 0.99 会怎样？
如果设为 0.5 会怎样？

你的想法：
_______________________________________________
```

```
数学练习：计算带 Momentum 的更新

假设：
- 当前梯度 grad = 0.5
- 当前动量 v = 0
- momentum = 0.9
- lr = 0.01

步骤1（第一步）：
v = 0.9 × 0 + 0.5 = 0.5
W = W - 0.01 × 0.5

步骤2（假设梯度变成 0.3）：
v = 0.9 × 0.5 + 0.3 = 0.75
W = W - 0.01 × 0.75

观察：
- 第二步的更新幅度变大了还是变小了？
- 为什么？（提示：看 v 的变化）

你的计算和想法：
_______________________________________________
```

#### Q3：Adam 的自适应学习率

```
问题：Adam 中的 "自适应" 是什么意思？

Adam = Momentum + 每个参数单独的学习率

Momentum 做了什么：
- 用历史梯度平滑当前更新

自适应学习率做了什么：
- 对每个参数，根据其历史梯度大小调整更新幅度

梯度大的参数 → 学习率变小
梯度小的参数 → 学习率变大

为什么要这样做？
如果所有参数都用同一个 lr，有什么问题？

你的想法：
_______________________________________________
```

```
Adam 的两个矩估计（简化理解）

m_t（一阶矩）：梯度平均值 → 类似 Momentum
v_t（二阶矩）：梯度平方平均值 → 记录梯度大小

m_t = β₁ × m_{t-1} + (1-β₁) × grad
v_t = β₂ × v_{t-1} + (1-β₂) × grad²

修正（防止训练初期值太小）：
m̂_t = m_t / (1-β₁^t)
v̂_t = v_t / (1-β₂^t)

更新：
W = W - lr × m̂_t / (√v̂_t + ε)

思考：
- β₁ 和 β₂ 通常设为什么值？（0.9, 0.999）
- ε = 1e-8 的作用是什么？
- 分母为什么要加 ε？

你的想法：
_______________________________________________
```

#### Q4：Warmup 的深层原因

```
问题：训练开始时，为什么需要 Warmup？

直接用大学习率会怎样？
直接用小学习率会怎样？
Warmup 从小到大再变大的逻辑是什么？

类比：开车起步
- 上来就踩油门（大学习率）：可能失控
- 慢慢提速（小学习率）：安全但慢
- 正常行驶（正常学习率）：既安全又快

这个类比和神经网络训练有什么相似之处？

你的想法：
_______________________________________________
```

```
更深入的问题：为什么训练初期梯度可能"不正常"？

假设网络参数初始值很小：
- 第一步前向：输出接近随机
- Loss 很大
- 梯度可能很大或很小
- 更新后参数可能跳到极端值

这会导致什么后果？
Warmup 如何缓解这个问题？

你的想法：
_______________________________________________
```

### 实践练习

| 练习 | 描述 | 验收标准 |
|------|------|---------|
| 练习 3.1 | 手写 SGD、Momentum、Adam | 能解释每行代码 |
| 练习 3.2 | 用 2D 损失函数可视化三种优化器 | 能画图对比 |
| 练习 3.3 | 解释为什么 Warmup 参数设 2000 而不是 200 | 有理论依据 |

---

## 第四章：数据工程的深层逻辑

> **核心认知**：大厂做预训练的人，80% 的时间花在数据上，不是模型架构。

### 学习目标

| 目标 | 描述 | 判断标准 |
|------|------|---------|
| 理解数据质量 | 知道什么是"好数据" | 能列举质量标准 |
| 理解去重原理 | 知道重复数据的危害 | 能解释记忆效应 |
| 理解数据配比 | 知道不同数据的作用 | 能设计配比实验 |

### 💭 引导思考问题

#### Q1：为什么重复数据是灾难？

```
问题：大模型有"记忆能力"，这意味着什么？

观察：如果你把同一段话读给大模型听 100 遍
- 第一次：正常学习
- 第十次：开始记住
- 第一百次：完全记住，可以逐字背诵

这意味着模型学到了什么？
"记住"和"理解"有什么区别？
考试时默写原文算是"智能"吗？

你的想法：
_______________________________________________
```

```
追问：如何检测重复数据？

假设你有 100 万条文本，如何找出重复的？

简单方法：逐条比较
- 时间复杂度：O(n² × L)，n=100万，L=平均长度
- 这在计算上可行吗？

更快的方法：MinHash / SimHash
- 核心思想：把长文本变成"指纹"
- 相似文本 → 相似指纹
- 用局部敏感哈希快速找相似对

MinHash 的直觉是什么？
为什么叫"局部敏感"？

你的想法：
_______________________________________________
```

#### Q2：什么是"数据质量"？

```
问题：什么样的数据算"高质量"？

从不同角度思考：
- 语言流畅度：语法正确、通顺
- 信息密度：有内容、有价值
- 多样性：不重复、覆盖面广
- 准确性：事实正确、信息真实
- 安全性：无有害内容

这五个维度同等重要吗？
哪个最重要？为什么？

你的想法：
_______________________________________________
```

```
追问：能不能用模型来评估数据质量？

用 AI 来筛选 AI 的训练数据

方法 1：用小模型打分
- 输入文本 → 模型打分 → 过滤低分

方法 2：困惑度 (PPL) 过滤
- PPL 极高：模型完全预测不了，可能是乱码
- PPL 极低：模型太熟悉，可能是重复内容

问题：谁来评估评估者？
PPL 低的就一定是好数据吗？

你的想法：
_______________________________________________
```

#### Q3：数据配比为什么重要？

```
问题：如果只用维基百科训练，会怎样？

维基百科的特点：
- 语言正式、书面化
- 事实性强、知识密集
- 缺少口语表达
- 缺少创意写作

模型会学到什么？
不会学到什么？

你的想法：
_______________________________________________
```

```
追问：为什么小说多了会"胡说八道"？

小说/故事的特点：
- 想象力丰富，但不必符合事实
- 情节可以虚构
- 语言夸张、富有表现力

如果训练数据中小说占 90%：
- 模型说话会像讲故事
- 可能编造事实（hallucination）
- 事实性问答能力下降

这说明什么？
数据配比如何影响模型行为？

你的想法：
_______________________________________________
```

### 实践练习

| 练习 | 描述 | 验收标准 |
|------|------|---------|
| 练习 4.1 | 下载一个小数据集（1MB），统计重复率 | 能解释方法 |
| 练习 4.2 | 实现 MinHash 去重算法 | 代码能运行 |
| 练习 4.3 | 设计一个数据配比实验 | 能说明假设和预期 |

---

# 💻 阶段二：代码实现

> **核心目标**：亲手实现每一个核心组件
> **框架选择**：基于 MLX（Apple Metal）或 纯 PyTorch (CPU/Metal)

---

## 第五章：手写训练框架

### 环境配置

```bash
# 检查 Metal 支持
python -c "import torch; print(torch.backends.mps.is_available())"

# 如果支持，安装 MLX（Apple 官方框架）
pip install mlx

# 或者用 llama.cpp（支持 Metal 推理）
brew install llama.cpp
```

### 组件实现清单

| 组件 | 必做程度 | 预计时间 |
|------|---------|---------|
| Tokenizer（BPE） | ⭐⭐⭐⭐⭐ | 3小时 |
| Dataset + DataLoader | ⭐⭐⭐⭐⭐ | 2小时 |
| Transformer Block | ⭐⭐⭐⭐ | 4小时 |
| Attention 实现 | ⭐⭐⭐⭐⭐ | 3小时 |
| Positional Encoding | ⭐⭐⭐⭐ | 1小时 |
| Optimizer (SGD/Adam) | ⭐⭐⭐⭐⭐ | 2小时 |
| Training Loop | ⭐⭐⭐⭐⭐ | 2小时 |
| Metal 加速 | ⭐⭐⭐ | 4小时 |

### 💭 引导问题（实现前）

```
在写代码之前，先思考：

Q: Transformer 的核心参数有哪些？

模型大小相关：
- 层数 (n_layers)：12, 24, 32...
- 隐藏层维度 (d_model)：768, 1024, 2048...
- Attention 头数 (n_heads)：8, 16, 32...
- Feedforward 维度 (d_ff)：3072, 4096...

这些参数之间有关系吗？
为什么 d_ff 通常是 d_model 的 4 倍？
层数和宽度，哪个更重要？

你的初步选择（我们要训练一个 mini 模型）：
- n_layers: ___
- d_model: ___
- n_heads: ___
- d_ff: ___
```

```
Q: 显存/内存预算是多少？

Mac Studio M2 Ultra:
- 统一内存：最高 128GB
- Metal GPU：共享内存

模型参数量估算：
- 参数量 ≈ 12 × d_model² × n_layers（简化）
- 对于 d_model=256, n_layers=4:
  参数量 ≈ 12 × 256² × 4 ≈ 3M 参数

训练显存 ≈ 参数 × 20（简化估计）
- 3M 参数 → 60MB（很小！）
- 100M 参数 → 2GB
- 500M 参数 → 10GB

我们选择训练多少参数的模型？
___M 参数（建议：50M - 200M）

你的选择：___
```

### 代码练习：逐个击破

#### 练习 5.1：BPE Tokenizer 实现

```
目标：实现一个简单的 BPE 分词器

核心逻辑：
1. 统计所有相邻字符对的频率
2. 合并频率最高的字符对
3. 重复直到达到目标词表大小

关键问题：如何高效合并？

数据结构建议：
- 词表：Dict[int, bytes] 或 Dict[int, str]
- 合并规则：Dict[Tuple[int, int], int]

实现步骤：
Step 1: 初始化（每个字符一个 token）
Step 2: 统计相邻对频率
Step 3: 找出最高频的对并合并
Step 4: 更新词表和合并规则
Step 5: 编码/解码函数

验收标准：
- 能对任意文本分词
- 能还原原始文本
- 能解释每行代码
```

```python
# 练习 5.1 框架

class SimpleBPE:
    def __init__(self, vocab_size=1000):
        self.vocab_size = vocab_size
        self.token_to_char = {}  # token -> char(s)
        self.char_to_token = {}  # char(s) -> token
        self.merge_rules = {}    # (t1, t2) -> new_token
    
    def train(self, text):
        """训练 BPE 分词器"""
        pass
    
    def encode(self, text):
        """将文本编码为 token 序列"""
        pass
    
    def decode(self, tokens):
        """将 token 序列解码为文本"""
        pass
```

#### 练习 5.2：Transformer Block 实现

```
目标：实现一个 Transformer Encoder Block

核心组件：
1. Multi-Head Self-Attention
2. Add & Norm
3. Feed-Forward Network
4. Add & Norm

    Input
      ↓
  Self-Attention + Add & Norm
      ↓
      FFN + Add & Norm
      ↓
    Output

关键设计决策：
- 使用什么归一化？（LayerNorm / RMSNorm）
- Attention 中 Q, K, V 如何计算？
- FFN 的激活函数选什么？（ReLU / GELU / SwiGLU）
```

```python
# 练习 5.2 框架

import torch
import torch.nn as nn
import torch.nn.functional as F

class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        
        self.W_Q = nn.Linear(d_model, d_model)
        self.W_K = nn.Linear(d_model, d_model)
        self.W_V = nn.Linear(d_model, d_model)
        self.W_O = nn.Linear(d_model, d_model)
    
    def forward(self, x, mask=None):
        # 实现多头注意力
        pass

class TransformerBlock(nn.Module):
    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):
        super().__init__()
        self.attn = MultiHeadAttention(d_model, n_heads)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),
            nn.Linear(d_ff, d_model),
        )
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x, mask=None):
        # 实现 Block
        pass
```

#### 练习 5.3：完整训练 Loop

```
目标：实现完整的训练循环

核心组件：
1. 前向传播 → Loss 计算
2. 反向传播 → 参数更新
3. 日志记录 → 进度监控
4. Checkpoint 保存/加载

    Epoch Loop
        ↓
    Batch Loop
        ↓
    Forward → Loss
        ↓
    Backward → Optimizer Step
        ↓
    Log & Eval
        ↓
    Save Checkpoint
```

```python
# 练习 5.3 框架

def train(model, dataloader, optimizer, criterion, epochs, device):
    model.to(device)
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        for batch_idx, (inputs, targets) in enumerate(dataloader):
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            # 前向
            outputs = model(inputs)
            loss = criterion(outputs.view(-1, outputs.size(-1)), 
                           targets.view(-1))
            
            # 反向
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            total_loss += loss.item()
            
            # 每 100 步打印
            if batch_idx % 100 == 0:
                print(f"Epoch {epoch}, Step {batch_idx}, Loss: {loss.item():.4f}")
        
        # 每个 Epoch 结束
        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch} completed. Avg Loss: {avg_loss:.4f}")
```

### 💭 调试引导

```
遇到问题时的思考框架：

1. Loss 不下降？
   - 检查数据：tokenization 对吗？标签对吗？
   - 检查模型：参数初始化对吗？梯度在传播吗？
   - 检查优化器：lr 正常吗？optimizer 有问题吗？

2. Loss 爆炸 (NaN)？
   - lr 是否太大？
   - 输入是否有 NaN/Inf？
   - 梯度裁剪开启了吗？

3. Loss 不变？
   - 模型是否真的在学习？（检查梯度）
   - lr 是否太小？
   - 是否有 bug 阻止了更新？

4. 显存不够？
   - batch size 调小
   - 梯度累积
   - 检查是否有 tensor 没 detach
```

---

## 第六章：Metal 加速实践

### MLX 框架快速入门

```python
# MLX 示例：简单的矩阵乘法（Metal 加速）

import mlx.core as mx
import mlx.nn as nn
import time

# 创建大矩阵
N = 4096
A = mx.random.normal((N, N))
B = mx.random.normal((N, N))

# Metal 加速的矩阵乘法
start = time.time()
C = mx.matmul(A, B)
mx.eval(C)  # 强制同步执行
metal_time = time.time() - start

print(f"Metal time: {metal_time:.4f}s")
```

### 💭 引导问题

```
Q: Metal 加速和 CUDA 有什么区别？

从编程模型角度看：
- CUDA：NVIDIA 专用，需要 CUDA Toolkit
- Metal：Apple 专用，系统级集成

从生态角度看：
- CUDA：有 PyTorch、TensorFlow、DeepSpeed 完整支持
- Metal：MLX 是 Apple 官方新框架，生态还在建设中

从性能角度看：
- M2 Ultra Metal：理论性能约 27 TFLOPS
- A100 CUDA：理论性能约 312 TFLOPS

差距很大，但我们能学到什么？

核心概念是相通的：
- Kernel 函数
- Memory Transfer
- 并行计算

你的理解：
_______________________________________________
```

---

# 🧪 阶段三：实验验证

> **核心目标**：故意制造事故，深度理解每个参数的作用
> **核心理念**：亲眼见证 → 思考原因 → 设计监控 → 记录结论

---

## 第九章：故意制造事故

### 必做实验清单

> **重要**：每个实验都要做到"亲眼见证"

| 实验 | 操作 | 预期现象 | 验收标准 |
|------|------|---------|---------|
| 实验 9.1 | 学习率 × 10 | Loss 爆炸/NaN | 截图 + 解释原因 |
| 实验 9.2 | 学习率 × 0.1 | Loss 几乎不变 | 截图 + 解释原因 |
| 实验 9.3 | 去掉 Warmup | 初期剧烈震荡 | 截图 + 解释原因 |
| 实验 9.4 | Batch Size = 1 | 收敛极慢/震荡大 | 截图 + 解释原因 |
| 实验 9.5 | 去掉 Gradient Clip | 可能 Loss 爆炸 | 截图 + 解释原因 |
| 实验 9.6 | 使用错误 Loss | 模型不收敛 | 截图 + 解释原因 |

### 实验记录模板

```markdown
## 实验名称：XXX

### 实验设置
- 模型：___M 参数
- 数据：___ 数据集
- 正常配置：
  - 学习率：___
  - Batch Size：___
  - Warmup：___
- 本次实验改动：
  - ___ = ___

### 实验结果
- Loss 曲线截图
- 最终 Loss：___
- 收敛步数：___

### 现象描述
用文字描述你观察到的现象：
_______________________________________________
_______________________________________________

### 原因分析
为什么会这样？
_______________________________________________
_______________________________________________

### 收获
这个实验教会了我什么？
_______________________________________________
_______________________________________________

### 如果要修复，应该怎么做？
_______________________________________________
_______________________________________________
```

### 💭 实验前的思考

```
实验 9.1：学习率灾难

在动手之前，预测会发生什么？

我的预测：
- Loss 会：上升 / 下降 / 震荡 / NaN
- 速度：变快 / 变慢 / 不变
- 其他现象：________________

实际发生的情况：
- Loss：________________
- 速度：________________
- 其他现象：________________

预测对了吗？如果不对，为什么？

我的反思：
_______________________________________________
```

```
追问：为什么学习率太大会导致 Loss 爆炸？

从数学角度：
- 参数更新：W_new = W_old - lr × grad
- 如果 lr 太大：
  - 一步跨过了最优解
  - 可能跳到 loss 更高的位置
  - 反复横跳，越来越远

从几何角度：
- Loss 曲面像山谷
- 太小：慢慢走
- 正好：快速下山
- 太大：跨过山谷到对面山上

你的理解：
_______________________________________________
```

---

## 第十章：系统性对比实验

### 实验设计原则

```
好的对比实验 = 控制变量 + 明确假设 + 可测量结果

错误示范：
- 同时改学习率和 batch size
- 不记录具体数值
- 没有明确假设

正确示范：
- 只改学习率，其他保持不变
- 假设"大学习率收敛更快"
- 记录每个配置的 Loss 曲线
```

### 推荐对比实验

| 实验 | 变量 | 固定变量 | 假设 | 测量指标 |
|------|------|---------|------|---------|
| 10.1 | 学习率 | 其他不变 | 最佳 lr 是？ | 收敛速度 + 最终 Loss |
| 10.2 | Batch Size | 其他不变 | 最佳 batch？ | 显存 + 收敛曲线 |
| 10.3 | Warmup 步数 | 其他不变 | 需要多长？ | 初期 Loss 曲线 |
| 10.4 | 数据量 | 其他不变 | 数据越多越好？ | Loss 下降速度 |

### 记录表格模板

```markdown
## 对比实验：学习率

### 实验设置
- 模型：___M
- 数据：___B tokens
- 固定参数：batch=___, warmup=___

### 实验结果

| 学习率 | 最终 Loss | 收敛步数 | Loss 曲线截图 |
|--------|----------|---------|--------------|
| 1e-5   |          |         | [截图]       |
| 3e-5   |          |         | [截图]       |
| 1e-4   |          |         | [截图]       |
| 3e-4   |          |         | [截图]       |
| 1e-3   |          |         | [截图]       |

### 结论
- 最佳学习率：___
- 为什么这个值最优？
- 学习率和收敛速度的关系是线性的吗？

### 后续问题
- 如果换不同的模型，最佳 lr 还一样吗？
- 如果换不同的数据，最佳 lr 还一样吗？
```

---

## 第十一章：复盘与面试素材

### 复盘文档结构

```markdown
# 我的预训练复盘

## 1. 基本信息
- 训练时间：___
- 硬件：Mac Studio M2 Ultra (___GB 内存)
- 模型规模：___M 参数
- 训练数据：___B tokens
- 总成本：___元（电费 + 时间）

## 2. 核心发现

### 2.1 关于学习率
- 我发现：___
- 这意味着：___
- 和网上说的对比：___

### 2.2 关于数据质量
- 我发现：___
- 这意味着：___
- 我的去重经验：___

### 2.3 关于训练稳定性
- 我遇到的问题：___
- 我的解决方案：___
- Google PaLM 也遇到过类似问题

## 3. 最有价值的教训

如果只能给面试官讲一个我的发现，那会是：
"我亲手验证了 XXX，这让我理解了 YYY"

## 4. 面试可以讲的"故事"

### 故事 1：那次 Loss 爆炸
- 背景：___
- 操作：___
- 现象：___
- 排查：___
- 解决：___
- 学到：___

### 故事 2：那次数据问题
- 背景：___
- 问题：___
- 发现过程：___
- 解决：___
- 学到：___

## 5. 如果重做一次

我会：
1. ___（避免的问题）
2. ___（先做的工作）
3. ___（不同的方法）

## 6. 未解决的问题

这些我还不懂，需要继续学习：
1. ___
2. ___
3. ___
```

### 面试问题清单

```
基于你的实验，你能回答这些问题吗？

Q1: "你的模型收敛时 Loss 是多少？和预期相比如何？"
我的答案：_______________________________________________

Q2: "训练过程中遇到过 Loss 爆炸吗？怎么排查的？"
我的答案：_______________________________________________

Q3: "你的学习率是怎么选的？有没有做实验对比？"
我的答案：_______________________________________________

Q4: "数据去重是怎么做的？重复数据对模型有什么影响？"
我的答案：_______________________________________________

Q5: "你了解 BF16 和 FP16 的区别吗？在 Metal 上怎么用？"
我的答案：_______________________________________________

Q6: "你的训练吞吐量是多少？MFU 有多少？优化过吗？"
我的答案：_______________________________________________

Q7: "Checkpoint 策略是怎么设计的？存多频繁？"
我的答案：_______________________________________________

Q8: "如果训练过程中发现收敛变慢，你怎么判断原因？"
我的答案：_______________________________________________
```

---

# 📦 附录：实用工具与资源

## A. 本地工具清单

| 工具 | 安装 | 用途 |
|------|------|------|
| Python 3.10+ | brew install python | 运行环境 |
| PyTorch (MPS) | pip install torch | 深度学习框架 |
| MLX | pip install mlx | Apple Metal 加速 |
| llama.cpp | brew install llama.cpp | 高效推理 |
| Weights & Biases | pip install wandb | 实验追踪 |
| htop | brew install htop | 系统监控 |
| nvitop | pip install nvitop | GPU 监控 |

## B. 推荐学习资源

| 资源 | 类型 | 推荐度 | 适合阶段 |
|------|------|-------|---------|
| The Illustrated Transformer | 可视化教程 | ⭐⭐⭐⭐⭐ | 原理理解 |
| CS231n 笔记 | 课程笔记 | ⭐⭐⭐⭐⭐ | 原理理解 |
| 《动手学深度学习》 | 书籍 | ⭐⭐⭐⭐ | 原理理解 |
| lit-gpt | 代码教程 | ⭐⭐⭐⭐⭐ | 代码实现 |
| MLX 官方示例 | 代码 | ⭐⭐⭐⭐ | Metal 实践 |
| HuggingFace 课程 | 课程 | ⭐⭐⭐⭐ | 全阶段 |

## C. 开源数据集

| 数据集 | 规模 | 特点 | 下载难度 |
|--------|------|------|---------|
| Tiny Stories | 10MB | 简单故事，适合测试 | ⭐ 极易 |
| Alpaca | 5MB | 指令数据 | ⭐ 极易 |
| OpenWebText | 80GB+ | 网页文本 | ⭐⭐ 简单 |
| FineWeb (sample) | 10GB | 高质量网页 | ⭐⭐ 简单 |

## D. 模型下载（可参考结构）

| 模型 | 参数量 | 用途 | Metal 兼容 |
|------|-------|------|-----------|
| TinyLlama-1.1B | 1.1B | 参考结构 | ✅ |
| GPT-2 Small | 124M | 学习结构 | ✅ |
| OPT-125M | 125M | 参考结构 | ✅ |

---

# 🎯 课程检查清单

## 开始前确认

- [ ] Mac Studio M2 Ultra 已配置好
- [ ] Python 3.10+ 环境已安装
- [ ] PyTorch 或 MLX 已安装（确认 MPS 可用）
- [ ] wandb 账号已注册
- [ ] 已下载一个小型测试数据集

## 阶段一完成标准

- [ ] 能手写 SGD 更新公式
- [ ] 能解释 Attention 的 Q/K/V
- [ ] 能解释 Warmup 的作用
- [ ] 能解释为什么需要数据去重
- [ ] 完成练习 1.1-1.3, 2.1-2.3, 3.1-3.3, 4.1-4.3

## 阶段二完成标准

- [ ] BPE Tokenizer 能正常工作
- [ ] Transformer Block 能正向传播
- [ ] 训练循环能跑通（Loss 下降）
- [ ] Metal 加速生效
- [ ] 完成练习 5.1-5.3

## 阶段三完成标准

- [ ] 至少完成 3 个"故意制造事故"实验
- [ ] 至少完成 1 个系统性对比实验
- [ ] 复盘文档已写完
- [ ] 能回答 5 个以上面试问题

---

> **最后提醒**：这个课程的目标不是"训练出世界最好的模型"，而是"亲手验证每一个核心概念"。每一个实验都要问"为什么"，每一个问题都要记录。这些才是真正有价值的经验。

---

*课纲创建时间：2026-02-09*
*基于「预训练面试重点」视频课程*
*适配硬件：Mac Studio (M2 Ultra)*
