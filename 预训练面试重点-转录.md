# 预训练面试重点 - 视频转录与分析

> 来源：~/Downloads/预训练面试重点.MP4（8分15秒）
> 转录时间：2026-02-09

---

## 📝 完整转录

面试大模型岗位时有个很苛刻的问题——你从零训练过模型吗？

我在面试别人的时候也很喜欢深挖候选人这方面的知识储备。但我发现大部分人都是根据自己看过的论文或技术博客来回答这个问题。目前的现状是，会做AI应用的人满地都是，跑过推理的人遍地都是，做过微调的人也不稀缺了，但真正从零训练过模型、真正踩过坑、能把预训练讲明白的人凤毛麟角。看过数十篇论文不如自己训过一次模型。

问题是大家都觉得预训练成本太高，动辄几百万算力预算，普通人根本摸不到。于是陷入一个死亡循环——不进大厂接触不到预训练，没有实战经验又进不了大厂。

今天我来告诉你怎么打破这个循环。在算力平台租几张卡，花一个月左右的时间，你就能把预训练的核心经验全部拿到手，而且根本花不了多少钱。

先打消一个误解——不是参数量大才撑得上经验。预训练的大部分坑，1B的模型会遇到，100B的模型也会遇到。当然规模大了会有一些新问题，但这些是更难，不是不同。核心的工程方法论是相通的。打个比方，你在驾校学会了开车，上路遇到的交通规则、突发情况处理、路况判断和老司机是一样的。区别只是老司机开的是复杂的拉力赛道，你开的是城市公路。但开车这件事你已经会了。你要向面试官证明的不是"我烧过多少钱"，而是"我知道怎么做"。

现在云算力平台已经很成熟了。80GB显存的A100或A800，租用价格大概在5到10块钱一小时。按6块钱算，一天跑满也就144块，一个月不到5000块。这个价格比很多人想象的低得多。如果想踩多机多卡分布式训练的坑，可以租更便宜的单卡组成集群来跑。总之花几千块钱换一个极其宝贵的预训练经验，投入产出比极高。

那现在问题来了——单卡A100 80GB显存到底能训多大的模型？简单算一下：模型参数本身占显存，1B参数用BF16存储大概占2GB。但训练不只是存参数，优化器状态、梯度、激活值这些加起来才是大头。用AdamW优化器的话，粗略估计1B模型训练大概需要20GB左右的显存。所以80GB的A100不做任何优化直接跑，大概能训3B到4B的模型。如果加上梯度检查点、混合精度、优化器状态卸载这些技巧，能把上限推到7B左右。

7B是什么概念？是目前私有化部署最常用的尺寸，也是开源社区最活跃的模型规模。这个规模的模型已经能涌现出相当不错的能力，足够你把预训练的核心流程全部走一遍。

有了硬件底座，接下来怎么干？千万别觉得到GitHub上随便拉一个训练框架把代码一跑等着loss下降就行了。那叫烧电费，无法攒经验。真正的经验是你能回答这些问题：

- 学习率怎么调？Warmup要多少步？为什么？
- 你训练的吞吐量是多少？tokens每秒？MFU大概多少？你觉得这个数值合理吗？有没有优化空间？
- 数据配比对模型能力有什么影响？怎么评估清洗之后数据的质量？
- 什么时候该存checkpoint？存得太频繁会怎样？
- 训练中后期loss下降变慢，怎么判断是正常的收敛减速，还是陷入了局部最优，还是学习率该decay了？
- BF16和FP16混合精度训练各有什么坑？什么情况下会出现数值不稳定？你是怎么处理的？

这些问题论文里不会细讲，博客里一笔带过，但面试官一定会问。因为这才是区分"真干过"和"只看过"的分水岭。

---

### 第一周：先搞数据工程

不着急采购GPU，先下载几个开源的预训练数据集。这里有个经验公式——训练所需的token数大约是模型参数量的20倍。比如训练1B的模型需要20B的token。目前开源的数据集很多都远超这个规模，比如SkyPile有150B token。

有个很反常识的认知：大厂里做预训练的人，占大头的工作并不是很多人想的那样每天看论文设计模型架构，而是**数据清洗和去重**。因为大模型有很强的记忆能力，一段话重复出现很多次它就记住了，开始复读，泛化能力直接归零。你要亲眼看到那些重复内容是如何污染训练集的，然后写脚本用MinHash或者SimHash做去重。这个过程会让你对"数据质量"四个字有切肤之痛的理解。

**分词**也值得深挖。分词的核心是信息压缩率。你可以试着训练一个自己的词表，对比不同词表大小的压缩率差异。当你的词表压缩率提升10%，意味着同样的文本能节省10%的训练算力。这笔账算清楚了，你就理解为什么各家都在词表上下功夫。

最后研究一下**数据配比**。小说多了说话流畅但开始胡说八道。你可以故意弄几个极端配比的数据集，留着后面做对比实验。

---

### 第二周：跑通流程，制造事故

这周开始上算力，真金白银开始烧了。先别急着训大的，找一个成熟的训练框架，用小参数量把完整流程跑通。

跑通之后最有价值的事情来了——**故意制造事故**：
- 把学习率调大10倍，看看loss会怎样
- 关掉warmup，观察训练初期的震荡
- 把batch size调得很小，感受梯度噪声
- 你要亲眼见证传说中的loss spike

然后思考怎么设计一套监控机制来捕捉这些异常。Checkpoint存多频繁才能在出事时快速回滚？这些问题想清楚了，你就理解了为什么大厂训练团队要花大量精力在训练稳定性上。

Google训练PaLM的时候，整个过程中出现了超过20次loss spike，每次都要回滚checkpoint、跳过问题batch才能恢复。这不是段子，是真实的工程挑战。

---

### 第三周：进入正式训练，深度调优

前两周的铺垫做完，这周开始认真训一个模型。建议从1B参数起步，这个规模在单卡A100上跑得动，训练周期也不会太长，方便你快速迭代。

训练过程中重点关注几件事：
- **学习率调度**：warmup步数，你可以试试不同的配置，观察收敛曲线的差异
- **梯度裁剪**：用来防止梯度爆炸，你可以试着关掉它看看会发生什么
- **Checkpoint策略**：存太频繁会浪费I/O，存太少出事了回滚代价大

这周结束你应该有一个训练到一定程度的模型，以及一份详细的训练日志。

---

### 第四周：评估与对比实验

做评估——文本生成、简单问答、代码补全。不用追求分数多高，关键是建立"改了什么→效果变了多少"的对应关系。

然后做对比实验：
- 把第一周准备的不同配比数据集拿出来，分别训练，对比效果差异
- 试试不同的学习率、不同的batch size
- 记录对收敛速度和最终效果的影响

这些对比实验的结论就是你面试时最硬的谈资。

最后写一份**复盘文档**，把整个过程中遇到的问题、尝试的解决方案、最终的结论都记下来。这份文档就是你的预训练经验证明。

---

## 💡 核心要点总结

### 1. 打破"预训练门槛高"的误区
- 1B模型的坑和100B模型的坑本质相同，核心工程方法论相通
- 单卡A100月租不到5000元，投入产出比极高

### 2. 显存估算公式
- 1B参数 BF16 ≈ 2GB 存储
- 训练显存 ≈ 参数存储 × 10-20倍（含优化器状态、梯度、激活值）
- 80GB A100：直接跑 3-4B，优化后可达 7B

### 3. 四周学习路线
| 周次 | 主题 | 核心任务 |
|------|------|---------|
| 第1周 | 数据工程 | 数据清洗、去重（MinHash）、分词、数据配比 |
| 第2周 | 跑通+制造事故 | 小模型跑通流程，故意触发各种训练问题 |
| 第3周 | 正式训练 | 1B模型训练，学习率调度、梯度裁剪、checkpoint策略 |
| 第4周 | 评估+对比 | 评估模型、对比实验、写复盘文档 |

### 4. 面试核心问题清单
- 学习率调度策略（warmup步数、decay策略）
- 训练吞吐量与MFU
- 数据质量评估与清洗方法
- Checkpoint策略设计
- Loss收敛异常诊断
- BF16 vs FP16 数值稳定性

### 5. 关键认知
- **数据清洗是预训练工作的大头**，不是模型架构设计
- **Chinchilla scaling law**：训练token数 ≈ 参数量 × 20
- **训练稳定性**是大厂最重视的工程能力（Google训练PaLM出现20+次loss spike）
- 面试要证明的是"我知道怎么做"，不是"我烧过多少钱"
